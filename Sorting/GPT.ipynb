{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbc5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aad3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caff501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deccbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='YOUR_KEY')\n",
    "\n",
    "# Set up YOUR OpenAI API key\n",
    "#OPENAI_API_KEY = \"YOUR_KEY\"\n",
    "# Set MODEL to \"gpt-3.5-turbo\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "# Set temperature to 0.9, it can be from 0~1, 0 is the most conservative, 1 is the most creative\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f3446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d22025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_8 = []\n",
    "rand_list_8_sorted = []\n",
    "n = 8\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_8.append(rand_list)\n",
    "    rand_list_8_sorted.append(rand_list.sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f972e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_12 = []\n",
    "rand_list_12_sorted = []\n",
    "n = 12\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_12.append(rand_list)\n",
    "    rand_list_12_sorted.append(rand_list.sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f623155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_16 = []\n",
    "rand_list_16_sorted = []\n",
    "n = 16\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_16.append(rand_list)\n",
    "    rand_list.sort()\n",
    "    rand_list_16_sorted.append(rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de914b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e7fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sorting_examples(n, m, rand_range):\n",
    "    rand_list_n = []\n",
    "    rand_list_sorted_n = []\n",
    "    for j in range(m):\n",
    "        rand_list = []\n",
    "        for i in range(n):\n",
    "            current = random.randint(rand_range[0],rand_range[1])\n",
    "            rand_list.append(current)\n",
    "        rand_list_n.append(rand_list)\n",
    "        rand_list.sort()\n",
    "        rand_list_sorted_n.append(rand_list)\n",
    "    return rand_list_n, rand_list_sorted_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f99e9-7406-4a35-ab11-c29deb9ba506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2116dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_IO(input='', num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"<Instruction> Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional text. </Instruction>\n",
    "\n",
    "<Examples>\n",
    "Input: [5, 1, 1, 2, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\n",
    "Output: [1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\n",
    "\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1]\n",
    "Output: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 9]\n",
    "\n",
    "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, 3, 8, 6, 7, 5, 8, 5, 0, 6, 3, 7, 0, 5, 3, 7, 5, 2, 4, 4, 9, 0, 7, 8, 2, 7, 7, 7, 2, 1, 3, 9, 9, 7, 9, 6, 6, 4, 5, 4, 2, 0, 8, 9, 0, 2, 2]\n",
    "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\"\"\"\n",
    "    \n",
    "    messages_in = [{\"role\": \"system\", \"content\": \\\n",
    "                     \"You are a faithful agent that answer mathematical questions accurately.\"},\\\n",
    "                {\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response_message = client.chat.completions.create(model=model, messages=messages_in, temperature=temperature)\n",
    "\n",
    "    response = response_message.choices[0].message.content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a4d439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_8, rand_list_8_sorted = gen_sorting_examples(8, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in tqdm(rand_list_8):\n",
    "    agent_answer.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422b89c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_8_sorted):\n",
    "    if ast.literal_eval(aa) == golden:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f9ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_12, rand_list_12_sorted = gen_sorting_examples(12, 100, rand_range)\n",
    "agent_answer_12 = []\n",
    "for rl in tqdm(rand_list_12):\n",
    "    agent_answer_12.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81fd9173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_12 = 0\n",
    "for aa, golden in zip(agent_answer_12, rand_list_12_sorted):\n",
    "    if ast.literal_eval(aa) == golden:\n",
    "        correct_12 += 1\n",
    "correct_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4679e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_16, rand_list_16_sorted = gen_sorting_examples(16, 100, rand_range)\n",
    "agent_answer_16 = []\n",
    "for rl in tqdm(rand_list_16):\n",
    "    agent_answer_16.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d028de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_16 = 0\n",
    "for aa, golden in zip(agent_answer_16, rand_list_16_sorted):\n",
    "    if ast.literal_eval(aa) == golden:\n",
    "        correct_16 += 1\n",
    "correct_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44be91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_20, rand_list_20_sorted = gen_sorting_examples(20, 100, rand_range)\n",
    "agent_answer_20 = []\n",
    "for rl in tqdm(rand_list_20):\n",
    "    agent_answer_20.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ea7afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_20 = 0\n",
    "for aa, golden in zip(agent_answer_20, rand_list_20_sorted):\n",
    "    try:\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct_20 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5a60326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:04<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_32, rand_list_32_sorted = gen_sorting_examples(32, 100, rand_range)\n",
    "agent_answer_32 = []\n",
    "for rl in tqdm(rand_list_32):\n",
    "    agent_answer_32.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc8a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_32 = 0\n",
    "for aa, golden in zip(agent_answer_32, rand_list_32_sorted):\n",
    "    try:\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct_32 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b875bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c845fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_CoT_3Shot(input, num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"<Instruction> Sort the following list of numbers in ascending order. You can generate any intermediate lists, but the final output should be the sorted list of numbers, prefixed with \"Output: \". </Instruction>\n",
    "\n",
    "<Approach>\n",
    "To sort the list of numbers follow these steps:\n",
    "1. Split the list of numbers into two to four unsorted sublists, each containing an equal number of elements from the original list (make sure they don't overlap).\n",
    "2. Sort each of the unsorted sublists.\n",
    "3. Merge the sorted sublists into a single sorted list using the merging algorithm from merge sort.\n",
    "</Approach>\n",
    "\n",
    "<Examples>\n",
    "Input: [4, 5, 3, 3, 7, 3, 0, 5, 0, 2, 8, 0, 2, 1, 6, 9]\n",
    "Unsorted Subarrays:\n",
    "[4, 5, 3, 3, 7, 3, 0, 5]\n",
    "[0, 2, 8, 0, 2, 1, 6, 9]\n",
    "Sorted Subarrays:\n",
    "[0, 3, 3, 3, 4, 5, 5, 7]\n",
    "[0, 0, 1, 2, 2, 6, 8, 9]\n",
    "Output: [0, 0, 0, 1, 2, 2, 3, 3, 3, 4, 5, 5, 6, 7, 8, 9]\n",
    "\n",
    "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Unsorted Subarrays:\n",
    "[6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9]\n",
    "[2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Sorted Subarrays:\n",
    "[1, 4, 4, 5, 5, 6, 6, 6, 6, 7, 7, 8, 9, 9, 9, 9]\n",
    "[0, 1, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 9]\n",
    "Output: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9]\n",
    "\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1, 9, 3, 1, 8, 1, 8, 6, 0, 1, 6, 1, 7, 4, 4, 6, 3, 3, 7, 9, 3, 6, 0, 3, 4, 5, 6, 6, 9, 9, 9, 7, 3]\n",
    "Unsorted Subarrays:\n",
    "[3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
    "[4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1]\n",
    "[9, 3, 1, 8, 1, 8, 6, 0, 1, 6, 1, 7, 4, 4, 6, 3]\n",
    "[3, 7, 9, 3, 6, 0, 3, 4, 5, 6, 6, 9, 9, 9, 7, 3]\n",
    "Sorted Subarrays:\n",
    "[0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\n",
    "[0, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 9, 9]\n",
    "[0, 1, 1, 1, 1, 3, 3, 4, 4, 6, 6, 6, 7, 8, 8, 9]\n",
    "[0, 3, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 9, 9, 9, 9]\n",
    "Output: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\"\"\"\n",
    "    \n",
    "    messages_in = [{\"role\": \"system\", \"content\": \\\n",
    "                     \"You are a faithful agent that can sort a list of numbers accurately.\"},\\\n",
    "                {\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response_message = client.chat.completions.create(model=model, messages=messages_in, temperature=temperature)\n",
    "\n",
    "    response = response_message.choices[0].message.content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b273a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:42<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_8, rand_list_8_sorted = gen_sorting_examples(8, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in tqdm(rand_list_8):\n",
    "    try:\n",
    "        agent_answer.append(Answer_Agent_CoT_3Shot(str(rl), 1))\n",
    "    except:\n",
    "        agent_answer.append(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7433f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_8_sorted):\n",
    "    try:\n",
    "        aa = aa.split('Output: ')[1]\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct += 1\n",
    "    except:\n",
    "        continue\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "450ed356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:13<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_12, rand_list_12_sorted = gen_sorting_examples(12, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in tqdm(rand_list_12):\n",
    "    try:\n",
    "        agent_answer.append(Answer_Agent_CoT_3Shot(str(rl), 1))\n",
    "    except:\n",
    "        agent_answer.append(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc5718ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_12 = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_12_sorted):\n",
    "    try:\n",
    "        aa = aa.split('Output: ')[1]\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct_12 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5974ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_16, rand_list_16_sorted = gen_sorting_examples(16, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in tqdm(rand_list_16):\n",
    "    try:\n",
    "        agent_answer.append(Answer_Agent_CoT_3Shot(str(rl), 1))\n",
    "    except:\n",
    "        agent_answer.append(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a273c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_16 = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_16_sorted):\n",
    "    try:\n",
    "        aa = aa.split('Output: ')[1]\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct_16 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5d2a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:09<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_20, rand_list_20_sorted = gen_sorting_examples(20, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in tqdm(rand_list_20):\n",
    "    try:\n",
    "        agent_answer.append(Answer_Agent_CoT_3Shot(str(rl), 1))\n",
    "    except:\n",
    "        agent_answer.append(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13401850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_20 = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_20_sorted):\n",
    "    try:\n",
    "        aa = aa.split('Output: ')[1]\n",
    "        if ast.literal_eval(aa) == golden:\n",
    "            correct_20 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc32a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_answer.split(\"Output: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16fd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c04009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '###123###'\n",
    "ast.literal_eval(re.search('###(.*)###', s).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a40a430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3862a73-c59d-4ee9-a602-79a688b42b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "all_answer_lm3_text_io = []\n",
    "ori_answers_io = []\n",
    "all_counts = -1\n",
    "for s in tqdm(list(arc_challenge['validation'])[0:100]):\n",
    "    all_counts += 1\n",
    "    ori_question = s['question']\n",
    "\n",
    "    choices = s['choices']['text']\n",
    "    choices_text = ''\n",
    "    i = 65\n",
    "    for c in choices:\n",
    "        choices_text += f'{chr(i)}) {c}; '\n",
    "        i += 1\n",
    "\n",
    "    response = Answer_Agent_IO(ori_question, choices_text, 1)[0]\n",
    "    ori_answers_io.append(response)\n",
    "    try:\n",
    "        response_format = re.search('###(.*)###', response).group(1)\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response_format)\n",
    "        except:\n",
    "            answer_current = response_format\n",
    "        all_answer_lm3_text_io.append(answer_current)\n",
    "    except:\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response)\n",
    "            all_answer_lm3_text_io.append(answer_current)\n",
    "        except:\n",
    "            try:\n",
    "                response_format = response.split('Answer: ')[1]\n",
    "                answer_current = ast.literal_eval(response_format)\n",
    "                all_answer_lm3_text_io.append(answer_current)\n",
    "            except:\n",
    "                print('no answer provided')\n",
    "                print(response)\n",
    "                all_answer_lm3_text_io.append('')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538a6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "all_answer_lm3_text_cot_0s = []\n",
    "all_counts = -1\n",
    "\n",
    "for s in tqdm(list(arc_challenge['validation'])[0:100]):\n",
    "    all_counts += 1\n",
    "    ori_question = s['question']\n",
    "\n",
    "    choices = s['choices']['text']\n",
    "    choices_text = ''\n",
    "    i = 65\n",
    "    for c in choices:\n",
    "        choices_text += f'{chr(i)}) {c}; '\n",
    "        i += 1\n",
    "\n",
    "    response = Answer_Agent_CoT_0Shot(ori_question, choices_text, 1)[0]\n",
    "    try:\n",
    "        response_format = re.search('###(.*)###', response).group(1)\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response_format)\n",
    "        except:\n",
    "            answer_current = response_format\n",
    "        all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "    except:\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response)\n",
    "            all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "        except:\n",
    "            try:\n",
    "                response_format = response.split('Answer: ')[1]\n",
    "                answer_current = ast.literal_eval(response_format)\n",
    "                all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "            except:\n",
    "                print('no answer provided')\n",
    "                print(response)\n",
    "                all_answer_lm3_text_cot_0s.append('')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68872c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417c9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5997eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3981020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_io.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_io))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baf9e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_io_ori.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in ori_answers_io))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0249c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_cot_0Shot.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_cot_0s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "870c6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_cot_2Shot.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_cot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72edb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_golden.txt', 'w') as f:\n",
    "    f.write('\\n'.join(s['answerKey'] for s in list(arc_challenge['validation'])[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbf119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad673421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_debate(question='', prior=[], others='', num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"Given a question, and the reasoning processes from another agent, recheck your thoughts and answer. \\\n",
    "    Make sure to include your answer in the format: ###answer###. \\\n",
    "    Question: {question} \\\n",
    "    Reasoning from another agent: {others} \\\n",
    "    Thought: \\\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": \\\n",
    "                        \"You are a faithful agent that answer mathematical questions accurately.\"}]\n",
    "    for p in prior:\n",
    "        messages.append({\"role\": \"user\", \"content\": p})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=num_seq,\n",
    "    )\n",
    "\n",
    "    responses = []\n",
    "    n = 0\n",
    "    while n < num_seq:\n",
    "        responses.append(tokenizer.decode(outputs[n][input_ids.shape[-1]:], skip_special_tokens=True))\n",
    "        n += 1\n",
    "    \n",
    "    return responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
