{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbc5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aad3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caff501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ef41a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wang/zhenyub/condaenvs/cenv_x86/lib/python3.8/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessor, LogitsProcessorList\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb092dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "access_token = \"KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba0549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1dbf60b0af4dcaa051821ea4a448c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53de11e3a6b242fc84a33d092320bd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\", torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=\"auto\", token=access_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f3446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d22025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_8 = []\n",
    "rand_list_8_sorted = []\n",
    "n = 8\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_8.append(rand_list)\n",
    "    rand_list_8_sorted.append(rand_list.sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f972e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_12 = []\n",
    "rand_list_12_sorted = []\n",
    "n = 12\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_12.append(rand_list)\n",
    "    rand_list_12_sorted.append(rand_list.sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f623155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list_16 = []\n",
    "rand_list_16_sorted = []\n",
    "n = 16\n",
    "m = 10\n",
    "for j in range(m):\n",
    "    rand_list = []\n",
    "    rand_list_sorted = []\n",
    "    for i in range(n):\n",
    "        current = random.randint(0,9)\n",
    "        rand_list.append(current)\n",
    "    rand_list_16.append(rand_list)\n",
    "    rand_list.sort()\n",
    "    rand_list_16_sorted.append(rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de914b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8e7fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sorting_examples(n, m, rand_range):\n",
    "    rand_list_n = []\n",
    "    rand_list_sorted_n = []\n",
    "    for j in range(m):\n",
    "        rand_list = []\n",
    "        for i in range(n):\n",
    "            current = random.randint(rand_range[0],rand_range[1])\n",
    "            rand_list.append(current)\n",
    "        rand_list_n.append(rand_list)\n",
    "        rand_list.sort()\n",
    "        rand_list_sorted_n.append(rand_list)\n",
    "    return rand_list_n, rand_list_sorted_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f99e9-7406-4a35-ab11-c29deb9ba506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2116dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_IO(input='', num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"<Instruction> Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional text. </Instruction>\n",
    "\n",
    "<Examples>\n",
    "Input: [5, 1, 1, 2, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\n",
    "Output: [1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\n",
    "\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1]\n",
    "Output: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 9]\n",
    "\n",
    "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, 3, 8, 6, 7, 5, 8, 5, 0, 6, 3, 7, 0, 5, 3, 7, 5, 2, 4, 4, 9, 0, 7, 8, 2, 7, 7, 7, 2, 1, 3, 9, 9, 7, 9, 6, 6, 4, 5, 4, 2, 0, 8, 9, 0, 2, 2]\n",
    "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": \\\n",
    "                     \"You are a faithful agent that answer questions accurately.\"},\\\n",
    "                {\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=num_seq,\n",
    "    )\n",
    "\n",
    "    responses = []\n",
    "    n = 0\n",
    "    while n < num_seq:\n",
    "        responses.append(tokenizer.decode(outputs[n][input_ids.shape[-1]:], skip_special_tokens=True))\n",
    "        n += 1\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a4d439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_8, rand_list_8_sorted = gen_sorting_examples(8, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in rand_list_8:\n",
    "    agent_answer.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "422b89c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_8_sorted):\n",
    "    if ast.literal_eval(aa[0]) == golden:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71f9ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_12, rand_list_12_sorted = gen_sorting_examples(12, 100, rand_range)\n",
    "agent_answer_12 = []\n",
    "for rl in rand_list_12:\n",
    "    agent_answer_12.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81fd9173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_12 = 0\n",
    "for aa, golden in zip(agent_answer_12, rand_list_12_sorted):\n",
    "    if ast.literal_eval(aa[0]) == golden:\n",
    "        correct_12 += 1\n",
    "correct_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4679e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_16, rand_list_16_sorted = gen_sorting_examples(16, 100, rand_range)\n",
    "agent_answer_16 = []\n",
    "for rl in rand_list_16:\n",
    "    agent_answer_16.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d028de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_16 = 0\n",
    "for aa, golden in zip(agent_answer_16, rand_list_16_sorted):\n",
    "    if ast.literal_eval(aa[0]) == golden:\n",
    "        correct_16 += 1\n",
    "correct_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44be91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_20, rand_list_20_sorted = gen_sorting_examples(20, 100, rand_range)\n",
    "agent_answer_20 = []\n",
    "for rl in rand_list_20:\n",
    "    agent_answer_20.append(Answer_Agent_IO(str(rl), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0ea7afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_20 = 0\n",
    "for aa, golden in zip(agent_answer_20, rand_list_20_sorted):\n",
    "    try:\n",
    "        if ast.literal_eval(aa[0]) == golden:\n",
    "            correct_20 += 1\n",
    "    except:\n",
    "        continue\n",
    "correct_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b875bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c845fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_CoT_3Shot(input, num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"<Instruction> Sort the following list of numbers in ascending order. You can generate any intermediate lists, but the final output should be the sorted list of numbers, prefixed with \"Output: \". </Instruction>\n",
    "\n",
    "<Approach>\n",
    "To sort the list of numbers follow these steps:\n",
    "1. Split the list of numbers into two to four unsorted sublists, each containing an equal number of elements from the original list (make sure they don't overlap).\n",
    "2. Sort each of the unsorted sublists.\n",
    "3. Merge the sorted sublists into a single sorted list using the merging algorithm from merge sort.\n",
    "</Approach>\n",
    "\n",
    "<Examples>\n",
    "Input: [4, 5, 3, 3, 7, 3, 0, 5, 0, 2, 8, 0, 2, 1, 6, 9]\n",
    "Unsorted Subarrays:\n",
    "[4, 5, 3, 3, 7, 3, 0, 5]\n",
    "[0, 2, 8, 0, 2, 1, 6, 9]\n",
    "Sorted Subarrays:\n",
    "[0, 3, 3, 3, 4, 5, 5, 7]\n",
    "[0, 0, 1, 2, 2, 6, 8, 9]\n",
    "Output: [0, 0, 0, 1, 2, 2, 3, 3, 3, 4, 5, 5, 6, 7, 8, 9]\n",
    "\n",
    "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Unsorted Subarrays:\n",
    "[6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9]\n",
    "[2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Sorted Subarrays:\n",
    "[1, 4, 4, 5, 5, 6, 6, 6, 6, 7, 7, 8, 9, 9, 9, 9]\n",
    "[0, 1, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 9]\n",
    "Output: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9]\n",
    "\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1, 9, 3, 1, 8, 1, 8, 6, 0, 1, 6, 1, 7, 4, 4, 6, 3, 3, 7, 9, 3, 6, 0, 3, 4, 5, 6, 6, 9, 9, 9, 7, 3]\n",
    "Unsorted Subarrays:\n",
    "[3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
    "[4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1]\n",
    "[9, 3, 1, 8, 1, 8, 6, 0, 1, 6, 1, 7, 4, 4, 6, 3]\n",
    "[3, 7, 9, 3, 6, 0, 3, 4, 5, 6, 6, 9, 9, 9, 7, 3]\n",
    "Sorted Subarrays:\n",
    "[0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\n",
    "[0, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 9, 9]\n",
    "[0, 1, 1, 1, 1, 3, 3, 4, 4, 6, 6, 6, 7, 8, 8, 9]\n",
    "[0, 3, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 9, 9, 9, 9]\n",
    "Output: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": \\\n",
    "                     \"You are a faithful agent that answer questions accurately.\"},\\\n",
    "                {\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=num_seq,\n",
    "    )\n",
    "\n",
    "    responses = []\n",
    "    n = 0\n",
    "    while n < num_seq:\n",
    "        responses.append(tokenizer.decode(outputs[n][input_ids.shape[-1]:], skip_special_tokens=True))\n",
    "        n += 1\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b273a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_range = [0,9]\n",
    "rand_list_8, rand_list_8_sorted = gen_sorting_examples(8, 100, rand_range)\n",
    "agent_answer = []\n",
    "for rl in rand_list_8:\n",
    "    try:\n",
    "        agent_answer.append(Answer_Agent_CoT_3Shot(str(rl), 1))\n",
    "    except:\n",
    "        agent_answer.append(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a7433f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for aa, golden in zip(agent_answer, rand_list_8_sorted):\n",
    "    if ast.literal_eval(aa[0]) == golden:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53dff2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1'],\n",
       " ['1']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6a2f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"To sort the list of numbers, we will follow the steps as described in the approach.\\n\\n1. Split the list of numbers into two unsorted sublists, each containing an equal number of elements from the original list (make sure they don't overlap).\\n2. Sort each of the unsorted sublists.\\n3. Merge the sorted sublists into a single sorted list using the merging algorithm from merge sort.\\n\\nHere are the steps for the given input:\\n\\nInput: [1, 5, 2, 6, 3, 7, 7, 4, 8, 2, 4, 3, 9, 6]\\n\\nSplitting the list into two sublists:\\nSublist 1: [1, 5, 2, 6, 3, 7, 7, 4]\\nSublist 2: [8, 2, 4, 3, 9, 6]\\n\\nSorting each sublist:\\nSublist 1: [1, 2, 3, 4, 5, 6, 7, 7]\\nSublist 2: [2, 3, 4, 6, 8, 9]\\n\\nMerging the sorted sublists:\\nMerging [1, 2, 3, 4, 5, 6, 7, 7] and [2, 3, 4, 6, 8, 9] into a single sorted list:\\n[1, 2, 2, 3, 3, 4, 4, 5, 6, 6, 7, 7, 8, 9]\\n\\nOutput: [1, 2, 2, 3, 3, 4, 4, 5, 6, 6, 7, 7, 8, 9]\",\n",
       " \"To sort the list of numbers, we will follow the steps outlined in the approach.\\n\\n1. Split the list of numbers into two unsorted sublists, each containing an equal number of elements from the original list (make sure they don't overlap).\\n2. Sort each of the unsorted sublists.\\n3. Merge the sorted sublists into a single sorted list using the merging algorithm from merge sort.\\n\\nHere are the steps to sort the list [1, 5, 2, 6, 3, 7, 7, 4, 8, 2, 4, 3, 9, 6]:\\n\\nUnsorted Subarrays:\\n[1, 5, 2, 6, 3, 7, 7, 4, 8]\\n[2, 4, 3, 9, 6]\\n\\nSorted Subarrays:\\n[1, 2, 3, 4, 5, 6, 7, 7, 8]\\n[2, 3, 4, 6, 9]\\n\\nNow, we will merge the two sorted sublists into a single sorted list:\\n\\nMerging:\\n- Compare 1 and 2, the smaller one is 1, add it to the result.\\n- Compare 2 and 2, the smaller one is 2, add it to the result.\\n- Compare 3 and 3, the smaller one is 3, add it to the result.\\n- Compare 4 and 4, the smaller one is 4, add it to the result.\\n- Compare 5 and 6, the smaller one is 5, add it to the result.\\n- Compare 6 and 7, the smaller one is 6, add it to the result.\\n- Compare 7 and 7, the smaller one is 7, add it to the result.\\n- Compare 8 and 9, the smaller one is 8, add it to the result.\\n\\nOutput: [1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 8, 9]\",\n",
       " \"To sort the list of numbers, we will follow the steps you provided.\\n\\n1. Split the list of numbers into two unsorted sublists, each containing an equal number of elements from the original list (make sure they don't overlap).\\n2. Sort each of the unsorted sublists.\\n3. Merge the sorted sublists into a single sorted list using the merging algorithm from merge sort.\\n\\nInput: [1, 5, 2, 6, 3, 7, 7, 4, 8, 2, 4, 3, 9, 6]\\n\\nUnsorted Subarrays:\\n[1, 5, 2, 6, 3, 7, 7, 4]\\n[8, 2, 4, 3, 9, 6]\\n\\nSorted Subarrays:\\n[1, 2, 3, 4, 5, 6, 7, 7]\\n[2, 3, 4, 6, 8, 9]\\n\\nNow, we will merge the sorted sublists into a single sorted list.\\n\\nMerging:\\n- Compare 1 and 2, take 1 (1)\\n- Compare 2 and 2, take 1 (1, 2)\\n- Compare 3 and 3, take 1 (1, 2, 3)\\n- Compare 4 and 4, take 1 (1, 2, 3, 4)\\n- Compare 5 and 6, take 5 (1, 2, 3, 4, 5)\\n- Compare 6 and 7, take 6 (1, 2, 3, 4, 5, 6)\\n- Compare 7 and 7, take 6 (1, 2, 3, 4, 5, 6, 7)\\n- Compare 7 and 8, take 7 (1, 2, 3, 4, 5, 6, 7, 7)\\n- Compare 8 and 9, take 8 (1, 2, 3, 4, 5, 6, 7, 7, 8)\\n- Compare 9 and 9, take 8 (1, 2, 3, 4, 5, 6, 7, 7, 8, 9)\\n- Compare \"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Answer_Agent_CoT_3Shot('[1, 5, 2, 6, 3, 7, 7, 4, 8, 2, 4, 3, 9, 6]', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc32a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_answer.split(\"Output: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16fd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c04009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '###123###'\n",
    "ast.literal_eval(re.search('###(.*)###', s).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a40a430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3862a73-c59d-4ee9-a602-79a688b42b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "all_answer_lm3_text_io = []\n",
    "ori_answers_io = []\n",
    "all_counts = -1\n",
    "for s in tqdm(list(arc_challenge['validation'])[0:100]):\n",
    "    all_counts += 1\n",
    "    ori_question = s['question']\n",
    "\n",
    "    choices = s['choices']['text']\n",
    "    choices_text = ''\n",
    "    i = 65\n",
    "    for c in choices:\n",
    "        choices_text += f'{chr(i)}) {c}; '\n",
    "        i += 1\n",
    "\n",
    "    response = Answer_Agent_IO(ori_question, choices_text, 1)[0]\n",
    "    ori_answers_io.append(response)\n",
    "    try:\n",
    "        response_format = re.search('###(.*)###', response).group(1)\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response_format)\n",
    "        except:\n",
    "            answer_current = response_format\n",
    "        all_answer_lm3_text_io.append(answer_current)\n",
    "    except:\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response)\n",
    "            all_answer_lm3_text_io.append(answer_current)\n",
    "        except:\n",
    "            try:\n",
    "                response_format = response.split('Answer: ')[1]\n",
    "                answer_current = ast.literal_eval(response_format)\n",
    "                all_answer_lm3_text_io.append(answer_current)\n",
    "            except:\n",
    "                print('no answer provided')\n",
    "                print(response)\n",
    "                all_answer_lm3_text_io.append('')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538a6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "all_answer_lm3_text_cot_0s = []\n",
    "all_counts = -1\n",
    "\n",
    "for s in tqdm(list(arc_challenge['validation'])[0:100]):\n",
    "    all_counts += 1\n",
    "    ori_question = s['question']\n",
    "\n",
    "    choices = s['choices']['text']\n",
    "    choices_text = ''\n",
    "    i = 65\n",
    "    for c in choices:\n",
    "        choices_text += f'{chr(i)}) {c}; '\n",
    "        i += 1\n",
    "\n",
    "    response = Answer_Agent_CoT_0Shot(ori_question, choices_text, 1)[0]\n",
    "    try:\n",
    "        response_format = re.search('###(.*)###', response).group(1)\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response_format)\n",
    "        except:\n",
    "            answer_current = response_format\n",
    "        all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "    except:\n",
    "        try:\n",
    "            answer_current = ast.literal_eval(response)\n",
    "            all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "        except:\n",
    "            try:\n",
    "                response_format = response.split('Answer: ')[1]\n",
    "                answer_current = ast.literal_eval(response_format)\n",
    "                all_answer_lm3_text_cot_0s.append(answer_current)\n",
    "            except:\n",
    "                print('no answer provided')\n",
    "                print(response)\n",
    "                all_answer_lm3_text_cot_0s.append('')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68872c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417c9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5997eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3981020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_io.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_io))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baf9e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_io_ori.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in ori_answers_io))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0249c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_cot_0Shot.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_cot_0s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "870c6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_lm3_cot_2Shot.txt', 'w') as f:\n",
    "    f.write('\\n'.join(str(ans) for ans in all_answer_lm3_text_cot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72edb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_golden.txt', 'w') as f:\n",
    "    f.write('\\n'.join(s['answerKey'] for s in list(arc_challenge['validation'])[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbf119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad673421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_Agent_debate(question='', prior=[], others='', num_seq=1):\n",
    "    message = \\\n",
    "    f\"\"\"Given a question, and the reasoning processes from another agent, recheck your thoughts and answer. \\\n",
    "    Make sure to include your answer in the format: ###answer###. \\\n",
    "    Question: {question} \\\n",
    "    Reasoning from another agent: {others} \\\n",
    "    Thought: \\\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": \\\n",
    "                        \"You are a faithful agent that answer mathematical questions accurately.\"}]\n",
    "    for p in prior:\n",
    "        messages.append({\"role\": \"user\", \"content\": p})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=num_seq,\n",
    "    )\n",
    "\n",
    "    responses = []\n",
    "    n = 0\n",
    "    while n < num_seq:\n",
    "        responses.append(tokenizer.decode(outputs[n][input_ids.shape[-1]:], skip_special_tokens=True))\n",
    "        n += 1\n",
    "    \n",
    "    return responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
